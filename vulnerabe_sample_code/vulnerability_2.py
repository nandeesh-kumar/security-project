# This code is for educational purposes only and demonstrates common vulnerabilities.
# DO NOT run this code in a production environment or with untrusted input.
# It is designed to be vulnerable to illustrate security concepts.

import os
import subprocess
import sqlite3
import re
import xml.etree.ElementTree as ET
import pickle
import base64
import json
import logging
import ldap3
from datetime import datetime, timedelta

# Configure logging for demonstration purposes
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class VulnerabilityExamples:

    def __init__(self):
        self.db_name = "vulnerable_database.db"
        self._initialize_database()

    def _initialize_database(self):
        """Initializes a vulnerable SQLite database."""
        conn = None
        try:
            conn = sqlite3.connect(self.db_name)
            cursor = conn.cursor()
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS users (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username TEXT NOT NULL UNIQUE,
                    password TEXT NOT NULL,
                    is_admin INTEGER DEFAULT 0
                )
            """)
            # Add some sample users for demonstration
            cursor.execute("INSERT OR IGNORE INTO users (username, password, is_admin) VALUES (?, ?, ?)", ("admin", "password123", 1))
            cursor.execute("INSERT OR IGNORE INTO users (username, password, is_admin) VALUES (?, ?, ?)", ("user", "userpass", 0))
            conn.commit()
            logging.info(f"Database '{self.db_name}' initialized successfully.")
        except sqlite3.Error as e:
            logging.error(f"Error initializing database: {e}")
        finally:
            if conn:
                conn.close()

    # 1. SQL Injection
    def sql_injection_vulnerable(self, username, password):
        """
        Vulnerable to SQL Injection.
        Attacker can bypass authentication by entering:
        username: ' OR 1=1 --
        password: any
        """
        logging.warning(f"--- Demonstrating SQL Injection ---")
        conn = None
        try:
            conn = sqlite3.connect(self.db_name)
            cursor = conn.cursor()
            # Insecurely concatenating user input directly into the query
            query = f"SELECT * FROM users WHERE username = '{username}' AND password = '{password}'"
            logging.info(f"Executing vulnerable SQL query: {query}")
            cursor.execute(query)
            result = cursor.fetchone()
            if result:
                logging.info(f"SQL Injection: Authentication successful for user: {result[1]}")
                return True
            else:
                logging.info("SQL Injection: Authentication failed.")
                return False
        except sqlite3.Error as e:
            logging.error(f"SQL Injection error: {e}")
            return False
        finally:
            if conn:
                conn.close()

    def sql_injection_safe(self, username, password):
        """
        Safe way to handle SQL queries using parameterized queries.
        """
        logging.info(f"--- Demonstrating Safe SQL Query (Parameterized) ---")
        conn = None
        try:
            conn = sqlite3.connect(self.db_name)
            cursor = conn.cursor()
            query = "SELECT * FROM users WHERE username = ? AND password = ?"
            cursor.execute(query, (username, password))
            result = cursor.fetchone()
            if result:
                logging.info(f"Safe SQL: Authentication successful for user: {result[1]}")
                return True
            else:
                logging.info("Safe SQL: Authentication failed.")
                return False
        except sqlite3.Error as e:
            logging.error(f"Safe SQL error: {e}")
            return False
        finally:
            if conn:
                conn.close()

    # 2. Cross-Site Scripting (XSS)
    def xss_vulnerable(self, user_input):
        """
        Vulnerable to Reflected XSS.
        If user_input contains <script>alert('XSS')</script>, it will be executed
        if rendered directly in a web browser without proper sanitization.
        """
        logging.warning(f"--- Demonstrating XSS ---")
        html_template = f"<h1>Hello, {user_input}</h1>"
        logging.info(f"Vulnerable HTML output (simulated): {html_template}")
        # In a real web application, this would be returned to the browser.
        return html_template

    def xss_safe(self, user_input):
        """
        Safe way to handle XSS by escaping HTML special characters.
        """
        logging.info(f"--- Demonstrating Safe XSS (HTML Escaping) ---")
        import cgi
        escaped_input = cgi.escape(user_input, quote=True)
        html_template = f"<h1>Hello, {escaped_input}</h1>"
        logging.info(f"Safe HTML output: {html_template}")
        return html_template

    # 3. Command Injection
    def command_injection_vulnerable(self, filename):
        """
        Vulnerable to Command Injection.
        Attacker can inject commands like 'file.txt; rm -rf /'
        """
        logging.warning(f"--- Demonstrating Command Injection ---")
        try:
            # Insecurely concatenating user input directly into a shell command
            command = f"ls -l {filename}"
            logging.info(f"Executing vulnerable command: {command}")
            result = subprocess.run(command, shell=True, capture_output=True, text=True, check=True)
            logging.info(f"Command Injection output:\n{result.stdout}")
            return result.stdout
        except subprocess.CalledProcessError as e:
            logging.error(f"Command Injection error: {e}\nStderr: {e.stderr}")
            return f"Error: {e.stderr}"
        except Exception as e:
            logging.error(f"Unexpected error in command injection: {e}")
            return f"Error: {e}"

    def command_injection_safe(self, filename):
        """
        Safe way to handle commands by passing arguments as a list.
        """
        logging.info(f"--- Demonstrating Safe Command Execution ---")
        try:
            # Pass arguments as a list to avoid shell interpretation
            command = ["ls", "-l", filename]
            logging.info(f"Executing safe command: {' '.join(command)}")
            result = subprocess.run(command, capture_output=True, text=True, check=True)
            logging.info(f"Safe Command output:\n{result.stdout}")
            return result.stdout
        except subprocess.CalledProcessError as e:
            logging.error(f"Safe Command error: {e}\nStderr: {e.stderr}")
            return f"Error: {e.stderr}"
        except Exception as e:
            logging.error(f"Unexpected error in safe command execution: {e}")
            return f"Error: {e}"

    # 4. Insecure Deserialization
    class InsecureObject:
        def __init__(self, message):
            self.message = message

        def __reduce__(self):
            # This is a dangerous __reduce__ method for demonstration.
            # An attacker could craft a payload to execute arbitrary code.
            # For example, to execute a command: (os.system, ('echo PWNED!',))
            return (print, (f"Deserialized message: {self.message}",))

    def insecure_deserialization_vulnerable(self, serialized_data):
        """
        Vulnerable to insecure deserialization using pickle.
        An attacker can craft a malicious pickle payload to execute arbitrary code.
        """
        logging.warning(f"--- Demonstrating Insecure Deserialization (Pickle) ---")
        try:
            # Dangerous: Deserializing untrusted data with pickle
            obj = pickle.loads(base64.b64decode(serialized_data))
            logging.info(f"Insecure Deserialization: Object loaded with message: {obj.message}")
            return obj.message
        except Exception as e:
            logging.error(f"Insecure Deserialization error: {e}")
            return f"Error: {e}"

    def insecure_deserialization_safe(self, serialized_json_data):
        """
        Safe way to handle data by using JSON (or other safe formats) instead of pickle.
        """
        logging.info(f"--- Demonstrating Safe Deserialization (JSON) ---")
        try:
            data = json.loads(serialized_json_data)
            message = data.get("message")
            logging.info(f"Safe Deserialization: Object loaded with message: {message}")
            return message
        except json.JSONDecodeError as e:
            logging.error(f"Safe Deserialization (JSON) error: {e}")
            return f"Error: Invalid JSON data: {e}"
        except Exception as e:
            logging.error(f"Unexpected error in safe deserialization: {e}")
            return f"Error: {e}"

    # 5. Broken Access Control
    def broken_access_control_vulnerable(self, user_id, requested_resource_id, is_admin_session):
        """
        Vulnerable to Broken Access Control.
        Allows a non-admin user to access an admin resource if they guess the ID.
        """
        logging.warning(f"--- Demonstrating Broken Access Control ---")
        if requested_resource_id == "admin_dashboard_data":
            if is_admin_session:
                logging.info(f"Broken Access Control: Admin user {user_id} accessing admin dashboard.")
                return "Admin Dashboard Data Accessed"
            else:
                logging.info(f"Broken Access Control: Non-admin user {user_id} attempting to access admin dashboard.")
                # This is the vulnerability: no proper check for actual administrative privileges,
                # just a simulated `is_admin_session`. A real vulnerability would be lacking a server-side check.
                return "Access Denied (simulated for non-admin)"
        else:
            logging.info(f"Broken Access Control: User {user_id} accessing resource {requested_resource_id}.")
            return f"Resource {requested_resource_id} accessed by user {user_id}"

    def broken_access_control_safe(self, user_id, requested_resource_id, actual_roles):
        """
        Safe way to handle access control by enforcing roles and permissions server-side.
        """
        logging.info(f"--- Demonstrating Safe Access Control ---")
        if requested_resource_id == "admin_dashboard_data":
            if "admin" in actual_roles:
                logging.info(f"Safe Access Control: Admin user {user_id} accessing admin dashboard.")
                return "Admin Dashboard Data Accessed"
            else:
                logging.info(f"Safe Access Control: Non-admin user {user_id} attempting to access admin dashboard. Access Denied.")
                return "Access Denied"
        else:
            logging.info(f"Safe Access Control: User {user_id} accessing resource {requested_resource_id}.")
            return f"Resource {requested_resource_id} accessed by user {user_id}"

    # 6. Security Misconfiguration
    def security_misconfiguration_vulnerable(self, log_level="DEBUG"):
        """
        Vulnerable to Security Misconfiguration (e.g., overly verbose logging in production).
        Exposing sensitive information through logs.
        """
        logging.warning(f"--- Demonstrating Security Misconfiguration ---")
        # In a real app, this would be configured globally.
        # For demonstration, we'll set it here temporarily.
        original_level = logging.getLogger().level
        logging.getLogger().setLevel(getattr(logging, log_level.upper(), logging.DEBUG))

        sensitive_data = {"user_id": 123, "password": "supersecretpassword", "api_key": "xyz123abc"}
        logging.debug(f"Vulnerable Log: Sensitive data logged at DEBUG level: {sensitive_data}")
        logging.info("Vulnerable Log: Application processed a request.")

        logging.getLogger().setLevel(original_level) # Reset for other examples
        return "Check logs for sensitive data exposure if log level is DEBUG."

    def security_misconfiguration_safe(self):
        """
        Safe way to handle security misconfiguration by using appropriate log levels
        and avoiding logging sensitive data.
        """
        logging.info(f"--- Demonstrating Safe Configuration (Logging) ---")
        # In production, logging level should be INFO or WARNING, not DEBUG.
        # Sensitive data should never be logged.
        logging.info("Safe Log: Application processed a request (no sensitive data).")
        return "No sensitive data logged at INFO level."

    # 7. XML External Entities (XXE)
    def xxe_vulnerable(self, xml_string):
        """
        Vulnerable to XML External Entity (XXE) attacks.
        Attacker can read local files or perform SSRF by including DTD with entities.
        Example payload:
        <?xml version="1.0"?>
        <!DOCTYPE foo [<!ENTITY xxe SYSTEM "file:///etc/passwd">]>
        <foo>&xxe;</foo>
        """
        logging.warning(f"--- Demonstrating XXE ---")
        try:
            # Dangerous: Not disabling external entity resolution
            parser = ET.XMLParser() # Default parser is vulnerable in older Python versions
            root = ET.fromstring(xml_string, parser=parser)
            logging.info(f"XXE: Parsed XML: {ET.tostring(root, encoding='unicode')}")
            return ET.tostring(root, encoding='unicode')
        except ET.ParseError as e:
            logging.error(f"XXE Parse Error: {e}")
            return f"Error parsing XML: {e}"
        except Exception as e:
            logging.error(f"Unexpected error in XXE: {e}")
            return f"Error: {e}"

    def xxe_safe(self, xml_string):
        """
        Safe way to handle XXE by disabling DTD and external entity resolution.
        """
        logging.info(f"--- Demonstrating Safe XXE (Disable DTD) ---")
        try:
            parser = ET.XMLParser(resolve_entities=False, dtd_validation=False)
            root = ET.fromstring(xml_string, parser=parser)
            logging.info(f"Safe XXE: Parsed XML: {ET.tostring(root, encoding='unicode')}")
            return ET.tostring(root, encoding='unicode')
        except ET.ParseError as e:
            logging.error(f"Safe XXE Parse Error: {e}")
            return f"Error parsing XML: {e}"
        except Exception as e:
            logging.error(f"Unexpected error in safe XXE: {e}")
            return f"Error: {e}"

    # 8. Server-Side Request Forgery (SSRF)
    def ssrf_vulnerable(self, url):
        """
        Vulnerable to SSRF.
        Attacker can force the server to make requests to internal services or
        other external hosts by providing an internal URL or IP address.
        """
        logging.warning(f"--- Demonstrating SSRF ---")
        try:
            import requests
            # Dangerous: Allowing arbitrary URLs to be fetched by the server
            logging.info(f"SSRF: Server making a request to: {url}")
            response = requests.get(url, timeout=5)
            logging.info(f"SSRF: Response status: {response.status_code}")
            logging.info(f"SSRF: Response content (first 100 chars): {response.text[:100]}...")
            return f"Fetched content from {url}. Status: {response.status_code}. Content excerpt: {response.text[:100]}..."
        except requests.exceptions.RequestException as e:
            logging.error(f"SSRF Request Error: {e}")
            return f"Error making request: {e}"
        except Exception as e:
            logging.error(f"Unexpected error in SSRF: {e}")
            return f"Error: {e}"

    def ssrf_safe(self, url):
        """
        Safe way to handle SSRF by validating and sanitizing URLs, or by
        using a whitelist of allowed domains.
        """
        logging.info(f"--- Demonstrating Safe SSRF (URL Validation) ---")
        allowed_domains = ["example.com", "api.publicservice.com"]
        parsed_url = None
        try:
            from urllib.parse import urlparse
            parsed_url = urlparse(url)
            if parsed_url.hostname not in allowed_domains:
                logging.error(f"SSRF Safe: Attempted to access disallowed domain: {parsed_url.hostname}")
                return "Error: Access to this domain is not allowed."

            import requests
            logging.info(f"Safe SSRF: Server making a request to: {url}")
            response = requests.get(url, timeout=5)
            logging.info(f"Safe SSRF: Response status: {response.status_code}")
            return f"Fetched content from {url}. Status: {response.status_code}. Content excerpt: {response.text[:100]}..."
        except requests.exceptions.RequestException as e:
            logging.error(f"Safe SSRF Request Error: {e}")
            return f"Error making request: {e}"
        except Exception as e:
            logging.error(f"Unexpected error in safe SSRF: {e}")
            return f"Error: {e}"


    # 9. Insecure Direct Object References (IDOR)
    def idor_vulnerable(self, user_id_from_session, requested_account_id):
        """
        Vulnerable to IDOR.
        An attacker can change 'requested_account_id' to access other users' data.
        """
        logging.warning(f"--- Demonstrating IDOR ---")
        accounts_data = {
            "user1": {"balance": 1000, "transactions": ["tx1", "tx2"]},
            "user2": {"balance": 500, "transactions": ["tx3", "tx4"]},
            "admin": {"balance": 9999, "transactions": ["admin_tx1", "admin_tx2"]}
        }
        # Direct access without checking if user_id_from_session owns requested_account_id
        if requested_account_id in accounts_data:
            logging.info(f"IDOR: User {user_id_from_session} requested data for account {requested_account_id}. Data: {accounts_data[requested_account_id]}")
            return accounts_data[requested_account_id]
        else:
            logging.info(f"IDOR: Account {requested_account_id} not found.")
            return "Account not found."

    def idor_safe(self, user_id_from_session, requested_account_id):
        """
        Safe way to handle IDOR by verifying ownership or authorization for the requested resource.
        """
        logging.info(f"--- Demonstrating Safe IDOR ---")
        user_ownership_map = {
            "user1": ["user1"],
            "user2": ["user2"],
            "admin": ["user1", "user2", "admin"] # Admin can access all
        }
        accounts_data = {
            "user1": {"balance": 1000, "transactions": ["tx1", "tx2"]},
            "user2": {"balance": 500, "transactions": ["tx3", "tx4"]},
            "admin": {"balance": 9999, "transactions": ["admin_tx1", "admin_tx2"]}
        }

        if requested_account_id in accounts_data and requested_account_id in user_ownership_map.get(user_id_from_session, []):
            logging.info(f"Safe IDOR: User {user_id_from_session} requested data for owned account {requested_account_id}. Data: {accounts_data[requested_account_id]}")
            return accounts_data[requested_account_id]
        else:
            logging.info(f"Safe IDOR: User {user_id_from_session} attempted to access unauthorized account {requested_account_id}. Access Denied.")
            return "Access Denied or Account not found."

    # 10. Missing Function Level Access Control (often covered by BAC)
    # This is often a sub-category of Broken Access Control.
    # It refers to situations where authentication is present, but authorization checks
    # are missing at the function/API level, allowing regular users to call admin functions.

    # Example: A function that should only be accessible by admins.
    def admin_only_function_vulnerable(self, user_role):
        """
        Vulnerable: No proper role check for an admin function.
        """
        logging.warning(f"--- Demonstrating Missing Function Level Access Control ---")
        logging.info(f"Vulnerable Admin Function: User with role '{user_role}' attempting to perform admin action.")
        # In a real app, this function would perform a critical admin task.
        logging.info("Vulnerable: Admin action performed (simulated) without strict role check.")
        return "Admin action performed (potentially by unauthorized user)."

    def admin_only_function_safe(self, user_role):
        """
        Safe: Enforcing role-based access control for an admin function.
        """
        logging.info(f"--- Demonstrating Safe Function Level Access Control ---")
        if user_role == "admin":
            logging.info(f"Safe Admin Function: Admin user performing admin action.")
            return "Admin action performed."
        else:
            logging.info(f"Safe Admin Function: Non-admin user '{user_role}' attempted to perform admin action. Access Denied.")
            return "Access Denied: Insufficient privileges."

    # 11. Sensitive Data Exposure
    def sensitive_data_exposure_vulnerable(self, user_data):
        """
        Vulnerable to Sensitive Data Exposure.
        Storing or transmitting sensitive data without proper encryption or hashing.
        """
        logging.warning(f"--- Demonstrating Sensitive Data Exposure ---")
        # Example: Storing passwords in plain text or with weak hashing
        password = user_data.get("password")
        if password:
            logging.info(f"Sensitive Data Exposure: Storing plain-text password: '{password}'")
            # In a real scenario, this would be written to a database or log file.
            return f"Password stored as plain text: {password}"
        return "No password provided."

    def sensitive_data_exposure_safe(self, user_data):
        """
        Safe way to handle sensitive data exposure by using strong hashing for passwords
        and proper encryption for other sensitive data at rest and in transit.
        """
        logging.info(f"--- Demonstrating Safe Sensitive Data Handling ---")
        password = user_data.get("password")
        if password:
            import bcrypt
            hashed_password = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
            logging.info(f"Safe Sensitive Data: Storing hashed password: '{hashed_password}'")
            # In a real scenario, this would be written to a database.
            return f"Password stored as bcrypt hash: {hashed_password}"
        return "No password provided."

    # 12. Cross-Site Request Forgery (CSRF)
    # CSRF typically requires a web application context to demonstrate effectively.
    # Here, we'll provide a conceptual example.

    def csrf_vulnerable_conceptual(self):
        """
        Conceptual demonstration of CSRF.
        Imagine a web application where a POST request like
        POST /transfer_funds HTTP/1.1
        Host: bank.com
        Content-Type: application/x-www-form-urlencoded
        Cookie: sessionid=abcdef123
        amount=100&to_account=attacker

        can be triggered by a malicious website without the user's explicit intent
        if the application doesn't have CSRF protection.
        """
        logging.warning(f"--- Demonstrating CSRF (Conceptual) ---")
        logging.info("Conceptual: A vulnerable web application might process a request initiated from an attacker's site.")
        logging.info("Protection involves CSRF tokens, SameSite cookies, and referrer checks.")
        return "CSRF vulnerability requires a web context for full demonstration."

    def csrf_safe_conceptual(self):
        """
        Conceptual demonstration of CSRF protection.
        A typical defense involves CSRF tokens.
        """
        logging.info(f"--- Demonstrating Safe CSRF (Conceptual with Token) ---")
        logging.info("Conceptual: A safe web application would require a unique, unguessable CSRF token with each sensitive request.")
        logging.info("The server verifies this token, preventing unauthorized cross-site requests.")
        return "CSRF protection typically uses anti-CSRF tokens."

    # 13. Using Components with Known Vulnerabilities
    def known_vulnerability_vulnerable(self):
        """
        Vulnerable: Using an outdated or known-vulnerable library/component.
        (e.g., an old version of Requests with known security issues, or a deprecated cryptographic library)
        This is conceptual as we can't force an old library version easily for demo.
        """
        logging.warning(f"--- Demonstrating Use of Components with Known Vulnerabilities ---")
        logging.info("Conceptual: Imagine using an older version of 'requests' library (e.g., < 2.20.0) that had known vulnerabilities.")
        logging.info("Or using a deprecated cryptographic hash like MD5 for password hashing.")
        # Example of a known vulnerable library (conceptually)
        # import some_old_vulnerable_library
        # some_old_vulnerable_library.do_something_insecure()
        return "This represents using outdated software components. Always keep libraries updated."

    def known_vulnerability_safe(self):
        """
        Safe: Keeping all dependencies and components updated to their latest, secure versions.
        """
        logging.info(f"--- Demonstrating Safe Component Usage ---")
        logging.info("Always update your libraries and frameworks to the latest secure versions.")
        logging.info("Regularly audit dependencies for known vulnerabilities using tools like Snyk or OWASP Dependency-Check.")
        return "Using up-to-date and patched software components."

    # 14. Insufficient Logging & Monitoring
    def insufficient_logging_vulnerable(self):
        """
        Vulnerable: Missing or inadequate logging of security-relevant events.
        Makes it difficult to detect, analyze, and recover from attacks.
        """
        logging.warning(f"--- Demonstrating Insufficient Logging & Monitoring ---")
        # Simulate a critical event without proper logging
        # For example, a failed login attempt that isn't logged
        logging.debug("Vulnerable: A critical event occurred (e.g., failed login), but only debug level logging is present.")
        return "Security-relevant events are not adequately logged."

    def insufficient_logging_safe(self):
        """
        Safe: Comprehensive logging and monitoring of security-relevant events.
        """
        logging.info(f"--- Demonstrating Sufficient Logging & Monitoring ---")
        # Log successful and failed login attempts, access to sensitive data, etc.
        logging.info("Safe: User 'johndoe' successfully logged in.")
        logging.warning("Safe: Failed login attempt for user 'bad_actor' from IP 192.168.1.100.")
        logging.info("Safe: Admin 'alice' accessed sensitive user data.")
        return "Security-relevant events are properly logged and monitored."

    # 15. Unvalidated Redirects and Forwards
    def unvalidated_redirect_vulnerable(self, redirect_url):
        """
        Vulnerable to Unvalidated Redirects.
        An attacker can redirect users to a malicious site by crafting a URL.
        """
        logging.warning(f"--- Demonstrating Unvalidated Redirects and Forwards ---")
        # In a web framework, this would be `return redirect(redirect_url)`
        logging.info(f"Vulnerable Redirect: Redirecting to: {redirect_url}")
        return f"Simulating redirect to: {redirect_url}"

    def unvalidated_redirect_safe(self, redirect_url):
        """
        Safe way to handle unvalidated redirects by whitelisting or validating target URLs.
        """
        logging.info(f"--- Demonstrating Safe Redirects ---")
        allowed_domains = ["trusted-domain.com", "another-safe-site.org"]
        parsed_url = None
        try:
            from urllib.parse import urlparse
            parsed_url = urlparse(redirect_url)
            if parsed_url.netloc not in allowed_domains:
                logging.error(f"Safe Redirect: Attempted to redirect to disallowed domain: {parsed_url.netloc}")
                return "Error: Redirect to this domain is not allowed."
            logging.info(f"Safe Redirect: Redirecting to: {redirect_url}")
            return f"Simulating safe redirect to: {redirect_url}"
        except Exception as e:
            logging.error(f"Error parsing redirect URL: {e}")
            return f"Error: Invalid redirect URL: {e}"

    # 16. LDAP Injection (if applicable to your environment)
    def ldap_injection_vulnerable(self, username, password):
        """
        Vulnerable to LDAP Injection.
        Attacker can bypass authentication or query arbitrary LDAP objects.
        Example username payload: `*` or `*)(objectClass=*)`
        """
        logging.warning(f"--- Demonstrating LDAP Injection ---")
        try:
            # This requires an LDAP server to connect to.
            # For demonstration, we'll simulate the vulnerable filter construction.
            # In a real scenario, this would connect to an LDAP server like:
            # server = ldap3.Server('ldap://localhost:389')
            # conn = ldap3.Connection(server)
            # conn.bind()
            # search_filter = f"(&(uid={username})(userPassword={password}))"
            # conn.search('dc=example,dc=com', search_filter)

            search_filter = f"(&(uid={username})(userPassword={password}))"
            logging.info(f"Vulnerable LDAP Filter: {search_filter}")
            if username == "*" or username == "*)(objectClass=*)":
                logging.info("LDAP Injection: Authentication bypassed (simulated due to malicious filter).")
                return True
            logging.info("LDAP Injection: Attempting authentication with provided credentials.")
            return False
        except Exception as e:
            logging.error(f"LDAP Injection error: {e}")
            return f"Error: {e}"

    def ldap_injection_safe(self, username, password):
        """
        Safe way to handle LDAP queries by properly escaping user input.
        """
        logging.info(f"--- Demonstrating Safe LDAP Query ---")
        try:
            # Proper escaping of user input for LDAP filters
            escaped_username = ldap3.utils.conv.escape_filter_chars(username)
            escaped_password = ldap3.utils.conv.escape_filter_chars(password)
            search_filter = f"(&(uid={escaped_username})(userPassword={escaped_password}))"
            logging.info(f"Safe LDAP Filter: {search_filter}")
            logging.info("Safe LDAP: Authentication attempted with escaped credentials.")
            # In a real scenario, this would be used with ldap3.Connection.search()
            return True # Simulated success
        except Exception as e:
            logging.error(f"Safe LDAP error: {e}")
            return f"Error: {e}"

    # 17. Race Conditions
    def race_condition_vulnerable(self, account_balance, amount):
        """
        Vulnerable to a Race Condition when withdrawing funds.
        Two concurrent requests might read the same balance, both decide to withdraw,
        and both succeed, leading to a negative balance or overdraw.
        """
        logging.warning(f"--- Demonstrating Race Condition ---")
        current_balance = account_balance
        logging.info(f"Race Condition: Initial balance: {current_balance}, Attempting to withdraw: {amount}")

        # Simulate a small delay (e.g., network latency or database read)
        import time
        time.sleep(0.01)

        if current_balance >= amount:
            new_balance = current_balance - amount
            logging.info(f"Race Condition: New balance after withdrawal: {new_balance}")
            return new_balance
        else:
            logging.info(f"Race Condition: Insufficient funds.")
            return current_balance

    # For demonstrating the safe version, a lock mechanism is needed,
    # which is complex to show in a single function without threading.
    # Conceptually, it involves using locks (e.g., database transactions with row locks,
    # or explicit threading locks) to ensure atomicity.

    def race_condition_safe_conceptual(self):
        """
        Conceptual demonstration of safe race condition handling.
        Achieved using database transactions with proper locking mechanisms
        or mutexes in multi-threaded environments.
        """
        logging.info(f"--- Demonstrating Safe Race Condition (Conceptual) ---")
        logging.info("Conceptually, safe handling of race conditions involves locking resources.")
        logging.info("For database operations, use transactions with `SELECT ... FOR UPDATE` or similar.")
        logging.info("For in-memory operations, use threading.Lock or multiprocessing.Lock.")
        return "Safe handling of race conditions requires synchronization mechanisms."

    # Cleanup
    def cleanup(self):
        """Removes the demonstration database."""
        if os.path.exists(self.db_name):
            os.remove(self.db_name)
            logging.info(f"Cleaned up database: '{self.db_name}'")


def run_examples():
    vuln_examples = VulnerabilityExamples()

    print("\n--- SQL Injection Examples ---")
    vuln_examples.sql_injection_vulnerable("admin", "password123") # Correct credentials
    vuln_examples.sql_injection_vulnerable("' OR 1=1 --", "") # SQLi bypass
    vuln_examples.sql_injection_safe("admin", "password123")
    vuln_examples.sql_injection_safe("' OR 1=1 --", "")

    print("\n--- XSS Examples ---")
    vuln_examples.xss_vulnerable("World")
    vuln_examples.xss_vulnerable("<script>alert('XSS Vulnerable!');</script>")
    vuln_examples.xss_safe("World")
    vuln_examples.xss_safe("<script>alert('XSS Safe!');</script>")

    print("\n--- Command Injection Examples ---")
    # Create a dummy file for demonstration
    with open("test_file.txt", "w") as f:
        f.write("This is a test file.")
    vuln_examples.command_injection_vulnerable("test_file.txt")
    vuln_examples.command_injection_vulnerable("test_file.txt; echo 'Malicious command executed!' > malicious.txt")
    vuln_examples.command_injection_safe("test_file.txt")
    # Clean up dummy file
    if os.path.exists("test_file.txt"):
        os.remove("test_file.txt")
    if os.path.exists("malicious.txt"):
        os.remove("malicious.txt")


    print("\n--- Insecure Deserialization Examples ---")
    # Crafting a dangerous pickle payload (for demonstration, won't execute arbitrary code here)
    # A real attacker would craft a payload to execute os.system('malicious_command')
    # For this example, we'll demonstrate deserializing our vulnerable object.
    obj_to_serialize = vuln_examples.InsecureObject("Hello from serialized object!")
    serialized_obj = base64.b64encode(pickle.dumps(obj_to_serialize)).decode('utf-8')
    vuln_examples.insecure_deserialization_vulnerable(serialized_obj)

    safe_json_data = json.dumps({"message": "Hello from JSON!"})
    vuln_examples.insecure_deserialization_safe(safe_json_data)

    print("\n--- Broken Access Control Examples ---")
    # Simulate user sessions
    user_session_id = "user1"
    admin_session_id = "admin"

    print("\nVulnerable BAC:")
    print(vuln_examples.broken_access_control_vulnerable(user_session_id, "admin_dashboard_data", False)) # Non-admin trying to access admin data (simulated)
    print(vuln_examples.broken_access_control_vulnerable(admin_session_id, "admin_dashboard_data", True)) # Admin accessing admin data
    print(vuln_examples.broken_access_control_vulnerable(user_session_id, "user1_profile", False)) # User accessing their own profile

    print("\nSafe BAC:")
    user_roles = ["user"]
    admin_roles = ["user", "admin"]
    print(vuln_examples.broken_access_control_safe(user_session_id, "admin_dashboard_data", user_roles))
    print(vuln_examples.broken_access_control_safe(admin_session_id, "admin_dashboard_data", admin_roles))
    print(vuln_examples.broken_access_control_safe(user_session_id, "user1_profile", user_roles))

    print("\n--- Security Misconfiguration Examples ---")
    vuln_examples.security_misconfiguration_vulnerable(log_level="DEBUG")
    vuln_examples.security_misconfiguration_safe()

    print("\n--- XXE Examples ---")
    vulnerable_xml = """<?xml version="1.0"?>
    <!DOCTYPE foo [<!ENTITY xxe SYSTEM "file:///etc/passwd">]>
    <foo>&xxe;</foo>
    """
    safe_xml = """<?xml version="1.0"?>
    <data><item>value</item></data>
    """
    vuln_examples.xxe_vulnerable(vulnerable_xml)
    vuln_examples.xxe_safe(safe_xml)

    print("\n--- SSRF Examples ---")
    vuln_examples.ssrf_vulnerable("http://localhost:8000") # Replace with a local HTTP server for testing
    vuln_examples.ssrf_vulnerable("http://169.254.169.254/latest/meta-data/") # AWS Metadata Service (if running on EC2)
    vuln_examples.ssrf_safe("http://example.com") # Should be allowed
    vuln_examples.ssrf_safe("http://localhost:8000") # Should be blocked if not in whitelist

    print("\n--- IDOR Examples ---")
    print("Vulnerable IDOR:")
    print(vuln_examples.idor_vulnerable("user1", "user1")) # User accessing their own account
    print(vuln_examples.idor_vulnerable("user1", "user2")) # User accessing another user's account (vulnerable)
    print(vuln_examples.idor_vulnerable("user1", "admin")) # User accessing admin account (vulnerable)

    print("\nSafe IDOR:")
    print(vuln_examples.idor_safe("user1", "user1"))
    print(vuln_examples.idor_safe("user1", "user2"))
    print(vuln_examples.idor_safe("admin", "user1")) # Admin accessing user's account (allowed)

    print("\n--- Missing Function Level Access Control Examples ---")
    print("Vulnerable:")
    print(vuln_examples.admin_only_function_vulnerable("user"))
    print(vuln_examples.admin_only_function_vulnerable("admin"))
    print("\nSafe:")
    print(vuln_examples.admin_only_function_safe("user"))
    print(vuln_examples.admin_only_function_safe("admin"))

    print("\n--- Sensitive Data Exposure Examples ---")
    vuln_examples.sensitive_data_exposure_vulnerable({"password": "plain_text_password"})
    vuln_examples.sensitive_data_exposure_safe({"password": "secure_password"})

    print("\n--- CSRF Examples (Conceptual) ---")
    vuln_examples.csrf_vulnerable_conceptual()
    vuln_examples.csrf_safe_conceptual()

    print("\n--- Using Components with Known Vulnerabilities Examples ---")
    vuln_examples.known_vulnerability_vulnerable()
    vuln_examples.known_vulnerability_safe()

    print("\n--- Insufficient Logging & Monitoring Examples ---")
    vuln_examples.insufficient_logging_vulnerable()
    vuln_examples.insufficient_logging_safe()

    print("\n--- Unvalidated Redirects and Forwards Examples ---")
    vuln_examples.unvalidated_redirect_vulnerable("http://malicious.com/phish")
    vuln_examples.unvalidated_redirect_safe("http://trusted-domain.com/dashboard")
    vuln_examples.unvalidated_redirect_safe("http://evil.com/phish")

    print("\n--- LDAP Injection Examples ---")
    vuln_examples.ldap_injection_vulnerable("johndoe", "mypass")
    vuln_examples.ldap_injection_vulnerable("*)", "") # LDAP Injection payload
    vuln_examples.ldap_injection_safe("johndoe", "mypass")
    vuln_examples.ldap_injection_safe("*)", "")

    print("\n--- Race Condition Examples ---")
    initial_balance = 100
    withdrawal_amount = 60

    print("\nVulnerable Race Condition (simulated two concurrent withdrawals):")
    # Simulate two threads hitting the vulnerable function simultaneously
    # In a real scenario, you'd use actual threading/multiprocessing
    balance1 = vuln_examples.race_condition_vulnerable(initial_balance, withdrawal_amount)
    balance2 = vuln_examples.race_condition_vulnerable(balance1, withdrawal_amount) # Second withdrawal might succeed unexpectedly
    print(f"Final balance after simulated race: {balance2}")

    print("\nSafe Race Condition (Conceptual):")
    vuln_examples.race_condition_safe_conceptual()

    vuln_examples.cleanup()

if __name__ == "__main__":
    run_examples()